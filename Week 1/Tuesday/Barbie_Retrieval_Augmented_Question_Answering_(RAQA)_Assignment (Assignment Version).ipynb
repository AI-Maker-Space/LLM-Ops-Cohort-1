{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AI-Maker-Space/LLM-Ops-Vault/blob/main/Week%201/First%20Session/Barbie_Retrieval_Augmented_Question_Answering_(RAQA)_Assignment%20(Assignment%20Version).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Questioning Barbie Reviews with RAQA (Retrieval Augmented Question Answering)\n",
        "\n",
        "In the following notebook, you are tasked with creating a system that answers questions based on information found in reviews of the 2023 Barbie movie.\n",
        "\n",
        "## Build 锔\n",
        "\n",
        "There are 3 main tasks in this notebook:\n",
        "\n",
        "1. Obtain and parse reviews from a review website\n",
        "2. Create a Vectorstore from the reviews\n",
        "3. Create a `RetrievalQA` using the VectorStore\n",
        "\n",
        "## Ship \n",
        "\n",
        "Create a Hugging Face Space that hosts your application.\n",
        "\n",
        "## Share \n",
        "\n",
        "Make a social media post about your final application."
      ],
      "metadata": {
        "id": "PLi09z_3qW8O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">### Why RAQA and not RAG?\n",
        ">If we look at the original [paper](https://arxiv.org/abs/2005.11401), we find that RAG is a fairly specific and well defined term that isn't exactly the same as \"retrieve context, feed context to model in the prompt\".\n",
        ">For that reason, we're making the decision to delineate between \"actual\" RAG, and Retrieval Augmented Question Answering - which is not a well defined phrase."
      ],
      "metadata": {
        "id": "_BBraMxjrwOx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-task Work\n",
        "\n",
        "All we really need to do to get started is to get our prerequisites!\n",
        "\n",
        "We'll be leveraging `langchain` and `openai` today.\n",
        "\n",
        "Check out the docs:\n",
        "- [LangChain](https://docs.langchain.com/docs/)\n",
        "- [OpenAI](https://github.com/openai/openai-python)"
      ],
      "metadata": {
        "id": "zcL8585DsZML"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQa6rjDLqPCI"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U openai langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Open AI API Key:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wF8_ODX5h-P",
        "outputId": "f3395c72-029b-4e49-f0b9-aba7e3c2195f"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Open AI API Key:路路路路路路路路路路\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 1: Data Preparation\n",
        "\n",
        "In this task we'll be collecting, and then parsing, our data."
      ],
      "metadata": {
        "id": "FLrL342RtWxf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Scraping IMDB Reviews of Barbie\n",
        "\n",
        "We'll use some Selenium based trickery to get the reviews we need to make our application.\n",
        "\n",
        "Check out the docs here:\n",
        "- [Selenium](https://www.selenium.dev/documentation/)"
      ],
      "metadata": {
        "id": "zh8QTtMhzY_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U requests"
      ],
      "metadata": {
        "id": "PsGPV2zHuCj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U scrapy selenium"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCNCZdzrw81B",
        "outputId": "f74cc223-af93-491a-e92e-5d7ee1355d49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m281.4/281.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m93.3/93.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m400.2/400.2 kB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m74.6/74.6 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install chromium-chromedriver"
      ],
      "metadata": {
        "id": "evZzjyX6xTbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scrapy.selector import Selector\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "Niq6DKMOwPIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "driver = webdriver.Chrome(options=chrome_options)"
      ],
      "metadata": {
        "id": "k9AA_f-DxGyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://www.imdb.com/title/tt1517268/reviews/?ref_=tt_ov_rt\"\n",
        "driver.get(url)"
      ],
      "metadata": {
        "id": "IsjYL7K_y1ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sel = Selector(text = driver.page_source)\n",
        "review_counts = sel.css('.lister .header span::text').extract_first().replace(',','').split(' ')[0]\n",
        "more_review_pages = int(int(review_counts)/25)"
      ],
      "metadata": {
        "id": "XPGysdwuy190"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in tqdm(range(more_review_pages)):\n",
        "    try:\n",
        "        css_selector = 'load-more-trigger'\n",
        "        driver.find_element(By.ID, css_selector).click()\n",
        "    except:\n",
        "        pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGSJ0vuDy4D2",
        "outputId": "5bd75470-a74a-4b2c-ba76-a9025d71c79b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 44/44 [00:02<00:00, 16.57it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rating_list = []\n",
        "review_date_list = []\n",
        "review_title_list = []\n",
        "author_list = []\n",
        "review_list = []\n",
        "review_url_list = []\n",
        "error_url_list = []\n",
        "error_msg_list = []\n",
        "reviews = driver.find_elements(By.CSS_SELECTOR, 'div.review-container')\n",
        "\n",
        "for d in tqdm(reviews):\n",
        "    try:\n",
        "        sel2 = Selector(text = d.get_attribute('innerHTML'))\n",
        "        try:\n",
        "            rating = sel2.css('.rating-other-user-rating span::text').extract_first()\n",
        "        except:\n",
        "            rating = np.NaN\n",
        "        try:\n",
        "            review = sel2.css('.text.show-more__control::text').extract_first()\n",
        "        except:\n",
        "            review = np.NaN\n",
        "        try:\n",
        "            review_date = sel2.css('.review-date::text').extract_first()\n",
        "        except:\n",
        "            review_date = np.NaN\n",
        "        try:\n",
        "            author = sel2.css('.display-name-link a::text').extract_first()\n",
        "        except:\n",
        "            author = np.NaN\n",
        "        try:\n",
        "            review_title = sel2.css('a.title::text').extract_first()\n",
        "        except:\n",
        "            review_title = np.NaN\n",
        "        try:\n",
        "            review_url = sel2.css('a.title::attr(href)').extract_first()\n",
        "        except:\n",
        "            review_url = np.NaN\n",
        "        rating_list.append(rating)\n",
        "        review_date_list.append(review_date)\n",
        "        review_title_list.append(review_title)\n",
        "        author_list.append(author)\n",
        "        review_list.append(review)\n",
        "        review_url_list.append(review_url)\n",
        "    except Exception as e:\n",
        "        error_url_list.append(url)\n",
        "        error_msg_list.append(e)\n",
        "review_df = pd.DataFrame({\n",
        "    'Review_Date':review_date_list,\n",
        "    'Author':author_list,\n",
        "    'Rating':rating_list,\n",
        "    'Review_Title':review_title_list,\n",
        "    'Review':review_list,\n",
        "    'Review_Url':review_url\n",
        "    })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c46cAciBxr2C",
        "outputId": "d5a8737f-6162-434c-ef82-81317490960d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 125/125 [00:01<00:00, 77.82it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review_df"
      ],
      "metadata": {
        "id": "W9A0C1tbyfuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's save this `pd.DataFrame` as a `.csv` to our local session (this will be terminated when you terminate the Colab session) so we can leverage it in LangChain!\n",
        "\n",
        "Check out the docs if you get stuck:\n",
        "- [`to_csv()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html)"
      ],
      "metadata": {
        "id": "9gHLLYflzw_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### YOUR CODE HERE"
      ],
      "metadata": {
        "id": "N9FDhwbNz64p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Parsing\n",
        "\n",
        "Now that we have our data - let's go ahead and start parsing it into a more usable format for LangChain!\n",
        "\n",
        "We'll be using the `CSVLoader` for this application.\n",
        "\n",
        "We also want to be sure to track the sources that our review came from!\n",
        "\n",
        "Check out the docs here:\n",
        "- [`CSVLoader`](https://python.langchain.com/docs/integrations/document_loaders/csv)"
      ],
      "metadata": {
        "id": "JtBD1H8ezNLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders.csv_loader import CSVLoader"
      ],
      "metadata": {
        "id": "AdXub4CszAAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = CSVLoader(\n",
        "    file_path=# YOUR CODE HERE,\n",
        "    source_column=# YOUR CODE HERE\n",
        "    )\n",
        "\n",
        "data = # YOUR CODE HERE"
      ],
      "metadata": {
        "id": "piE3_eSi0KGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "id": "pvxnyjgh0TRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert len(data) == 125"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26SZD9zb3luR",
        "outputId": "1362d670-2218-4506-9e5b-125864d3bd9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "125"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have collected our review information into a loader - we can go ahead and chunk the reviews into more manageable pieces.\n",
        "\n",
        "We'll be leveraging the `RecursiveCharacterTextSplitter` for this task today.\n",
        "\n",
        "While splitting our text seems like a simple enough task - getting this correct/incorrect can have massive downstream impacts on your application's performance.\n",
        "\n",
        "You can read the docs here:\n",
        "- [RecursiveCharacterTextSplitter](https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/recursive_text_splitter)\n",
        "\n",
        "We want to split our documents into 1000 character length chunks, with 100 characters of overlap.\n",
        "\n",
        "> ### HINT:\n",
        ">It's always worth it to check out the LangChain source code if you're ever in a bind - for instance, if you want to know how to transform a set of documents, check it out [here](https://github.com/langchain-ai/langchain/blob/5e9687a196410e9f41ebcd11eb3f2ca13925545b/libs/langchain/langchain/text_splitter.py#L268C18-L268C18)"
      ],
      "metadata": {
        "id": "_CTameZZ0r76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = , # the character length of the chunk\n",
        "    chunk_overlap = , # the character length of the overlap between chunks\n",
        "    length_function = , # the length function\n",
        ")"
      ],
      "metadata": {
        "id": "uEgcUVtl00Xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = ### YOUR CODE HERE"
      ],
      "metadata": {
        "id": "y9RJUiUD2gS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(documents)"
      ],
      "metadata": {
        "id": "w-oWu5XT3IG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert len(documents) == 181"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6N4OXAhc3oIB",
        "outputId": "51e36049-38af-4b4d-e2c5-4b16a363f8e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "181"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With our documents transformed into more manageable sizes, and with the correct metadata set-up, we're now ready to move on to creating our VectorStore!"
      ],
      "metadata": {
        "id": "ylT4jwmx3zCb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2: Creating an \"Index\"\n",
        "\n",
        "The term \"index\" is used largely to mean: Structured documents parsed into a useful format for querying, retrieving, and use in the LLM application stack."
      ],
      "metadata": {
        "id": "9cB0L_CN38W5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Selecting Our VectorStore\n",
        "\n",
        "There are a number of different VectorStores, and a number of different strengths and weaknesses to each.\n",
        "\n",
        "In this notebook, we will be keeping it very simple by leveraging [Facebook AI Similarity Search](https://ai.meta.com/tools/faiss/#:~:text=FAISS%20(Facebook%20AI%20Similarity%20Search,more%20scalable%20similarity%20search%20functions.), or `FAISS`."
      ],
      "metadata": {
        "id": "GycdG53N4f9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U faiss-cpu tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5o4vwSn4hfe",
        "outputId": "62bf250d-1c4f-49c3-b154-71e52d530ddf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m\u001b[0m \u001b[32m0.0/250.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m41.0/250.1 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m\u001b[0m \u001b[32m250.1/250.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're going to be setting up our VectorStore with the OpenAI embeddings model. While this embeddings model does not need to be consistent with the LLM selection, it does need to be consistent between embedding our index and embedding our queries over that index.\n",
        "\n",
        "While we don't have to worry too much about that in this example - it's something to keep in mind for more complex applications.\n",
        "\n",
        "We're going to leverage a [`CacheBackedEmbeddings`](https://python.langchain.com/docs/modules/data_connection/caching_embeddings )flow to prevent us from re-embedding similar queries over and over again.\n",
        "\n",
        "Not only will this save time, it will also save us precious embedding tokens, which will reduce the overall cost for our application.\n",
        "\n",
        ">#### Note:\n",
        ">The overall cost savings needs to be compared against the additional cost of storing the cached embeddings for a true cost/benefit analysis. If your users are submitting the same queries often, though, this pattern can be a massive reduction in cost."
      ],
      "metadata": {
        "id": "CGU96p5R54Xz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.embeddings import CacheBackedEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.storage import LocalFileStore\n",
        "\n",
        "store = ### YOUR CODE HERE\n",
        "\n",
        "core_embeddings_model = ### YOUR CODE HERE\n",
        "\n",
        "embedder = CacheBackedEmbeddings.from_bytes_store(\n",
        "    ### YOUR CODE HERE,\n",
        "    ### YOUR CODE HERE,\n",
        "    ### YOUR CODE HERE\n",
        ")\n",
        "\n",
        "vector_store = ### YOUR CODE HERE"
      ],
      "metadata": {
        "id": "AOzZWPU05WLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we've created the VectorStore, we can check that it's working by embedding a query and retrieving passages from our reviews that are close to it."
      ],
      "metadata": {
        "id": "IGHzcE5i6fOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How is Will Ferrell in this movie?\"\n",
        "embedding_vector = core_embeddings_model.embed_query(query)\n",
        "docs = vector_store.similarity_search_by_vector(embedding_vector, k = 4)\n",
        "\n",
        "for page in docs:\n",
        "  print(page.page_content)"
      ],
      "metadata": {
        "id": "JLOvFNxA6ZSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how much time the `CacheBackedEmbeddings` pattern saves us:"
      ],
      "metadata": {
        "id": "ix4fyOUS-fU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit -n 1 -r 1\n",
        "query = \"I really wanted to enjoy this and I know that I am not the target audience but there were massive plot holes and no real flow.\"\n",
        "embedding_vector = core_embeddings_model.embed_query(query)\n",
        "docs = vector_store.similarity_search_by_vector(embedding_vector, k = 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLXFKzu--m81",
        "outputId": "042181f7-7b21-4e47-dd5f-451b217c1aba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "178 ms 卤 0 ns per loop (mean 卤 std. dev. of 1 run, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "query = \"I really wanted to enjoy this and I know that I am not the target audience but there were massive plot holes and no real flow.\"\n",
        "embedding_vector = core_embeddings_model.embed_query(query)\n",
        "docs = vector_store.similarity_search_by_vector(embedding_vector, k = 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCwtsJbc_KPd",
        "outputId": "92acfeb8-26e8-4dd8-d247-29fea2ca5187"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "147 ms 卤 21.2 ms per loop (mean 卤 std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, even over a significant number of runs - the cached query is significantly faster than the first instance of the query!\n",
        "\n",
        "With that, we're ready to move onto Task 3!"
      ],
      "metadata": {
        "id": "b4utL1EfARTm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 3: Building a Retrieval Chain\n",
        "\n",
        "In this task, we'll be making a Retrieval Chain which will allow us to ask semantic questions over our data.\n",
        "\n",
        "This part is rather abstracted away from us in LangChain and so it seems very powerful.\n",
        "\n",
        "Be sure to check the documentation, the source code, and other provided resources to build a deeper understanding of what's happening \"under the hood\"!"
      ],
      "metadata": {
        "id": "Po3kHNHGBp0j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### A Basic RetrievalQA Chain\n",
        "\n",
        "We're going to leverage `return_source_documents=True` to ensure we have proper sources for our reviews - should the end user want to verify the reviews themselves.\n",
        "\n",
        "Hallucinations [are](https://arxiv.org/abs/2202.03629) [a](https://arxiv.org/abs/2305.15852) [massive](https://arxiv.org/abs/2303.16104) [problem](https://arxiv.org/abs/2305.18248) in LLM applications.\n",
        "\n",
        "Though it has been tenuously shown that using Retrieval Augmentation [reduces hallucination in conversations](https://arxiv.org/pdf/2104.07567.pdf), one sure fire way to ensure your model is not hallucinating in a non-transparent way is to provide sources with your responses. This way the end-user can verify the output."
      ],
      "metadata": {
        "id": "i5Ux9XdzCDi9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Our LLM\n",
        "\n",
        "In this notebook, we'll continue to leverage OpenAI's suite of models - this time we'll be using the `gpt-3.5-turbo` model to power our RetrievalQAWithSources chain.\n",
        "\n",
        "Check out the relevant documentation if you get stuck:\n",
        "- [`OpenAIChat()`](https://python.langchain.com/docs/modules/model_io/models/chat/)"
      ],
      "metadata": {
        "id": "O_waVo3AEk71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms.openai import OpenAIChat\n",
        "\n",
        "llm = ### YOUR CODE HERE"
      ],
      "metadata": {
        "id": "QfglvbBtExPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can set up our chain.\n",
        "\n",
        "We'll need to make our VectorStore a retriever in order to be able to leverage it in our chain - let's check out the `as_retriever()` method.\n",
        "\n",
        "Relevant Documentation:\n",
        "- [`FAISS`](https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.faiss.FAISS.html#langchain.vectorstores.faiss.FAISS.as_retriever)"
      ],
      "metadata": {
        "id": "w35ZkVEoE8II"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vector_store.as_retriever()"
      ],
      "metadata": {
        "id": "T8TWJMH8F_w7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.callbacks import StdOutCallbackHandler\n",
        "\n",
        "handler = StdOutCallbackHandler()\n",
        "\n",
        "qa_with_sources_chain = RetrievalQA.from_chain_type(\n",
        "    llm=### YOUR CODE HERE,\n",
        "    retriever=### YOUR CODE HERE,\n",
        "    callbacks=[handler],\n",
        "    return_source_documents=True\n",
        ")"
      ],
      "metadata": {
        "id": "QeD8R6huFIf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_with_sources_chain({\"query\" : \"How was Will Ferrell in this movie?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqPaII9nF72R",
        "outputId": "0b46128f-edbe-4010-afdc-36603f25c4c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'How was Will Ferrell in this movie?',\n",
              " 'result': \"There are mixed opinions about Will Ferrell's performance in the movie. Some reviewers felt that his character was unnecessary and his presence detracted from the film, while others felt that his talents were underutilized.\",\n",
              " 'source_documents': [Document(page_content=\": 76\\nReview_Date: 23 July 2023\\nAuthor: a-hilton\\nRating: 10\\nReview_Title: Had me smiling all the way through\\nReview: Okay maybe it was a 9.5 because of two flaws: First was the Will Ferrell character and his board that made their point but then became superfluos. Second was that it is definitely not a kids' movie (although maybe they would see things that I didn't - I mean to be fair, the few kids in the theatre were well behaved so perhaps the movie got their full attention as well).\\nReview_Url: /review/rw9199947/?ref_=tt_urv\", metadata={'source': '/review/rw9199947/?ref_=tt_urv', 'row': 76}),\n",
              "  Document(page_content=': 85\\nReview_Date: 23 July 2023\\nAuthor: hyllus-01262\\nRating: 6\\nReview_Title: Overhyped movie, had its moments though\\nReview: The first half was pretty enjoyable, fun, light, but it took itself too seriously by the second half. No longer allowing the talented cast, especially Gosling, to shine and make us laugh. It felt like the talents of Will Ferrell and Michael Cera were also somewhat underutilized. Interesting concept, had potential, but later in the movie, it definitely started to fall flat for me.\\nReview_Url: /review/rw9199947/?ref_=tt_urv', metadata={'source': '/review/rw9199947/?ref_=tt_urv', 'row': 85}),\n",
              "  Document(page_content=\": 61\\nReview_Date: 23 July 2023\\nAuthor: agjbull\\nRating: 6\\nReview_Title: Just a little empty\\nReview: I really wanted to enjoy this and I know that I am not the target audience but there were massive plot holes and no real flow. The film was very disjointed. Ryan Gosling as good as he is seemed to old to play Ken and Will Ferrell ruined every scene he was in. I just didn't get it, it seemed hollow artificial and hackneyed. A waste of some great talent. It was predictable without being reassuring and trying so hard to be woke in the most superficial way in that but trying to tick so many boxes it actually ticked none. Margo Robbie looks beautiful throughout, the costumes and the sets were amazing but the story was way too weak and didn't make much sense at all.\\nReview_Url: /review/rw9199947/?ref_=tt_urv\", metadata={'source': '/review/rw9199947/?ref_=tt_urv', 'row': 61}),\n",
              "  Document(page_content=\"Review: The movie was very funny and really enjoyable to laugh at with the full theatre. However, the messages of the movie were the problem. I was never really sure what I was supposed to take away, there was nothing about finding equality or love it was all about how every man cat falls every woman or women can't be anything. It was really silly because there was no accurate reflection of America at any single point except for Barbie getting called a Fascist for no reason by a 14 year old. I enjoyed how they called out women for hating women and how they really tried to preach empowerment and the ability to be anything, but at the same time there was so much resentment and they ended the movie by reinstating hate. The majority of the movie was hating men as much as possible. That's just whatever because what really matters is the story. Well it fell short on that mark and it was really disappointing. The pacing was horrible, the villain won and was pretty irrelevant in the long run,\", metadata={'source': '/review/rw9199947/?ref_=tt_urv', 'row': 17})]}"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_with_sources_chain({\"query\" : \"Do reviewers consider this movie Kenough?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47Ov7N22MxOS",
        "outputId": "aeb6271b-4161-4921-e07c-b5f9041e9c4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'Do reviewers consider this movie Kenough?',\n",
              " 'result': 'Based on the provided reviews, three out of the four reviewers consider the movie \"Kenough.\" These reviewers gave it ratings of 8, 9, and 8 respectively. However, one reviewer gave it a rating of 6 and had several criticisms, suggesting that they did not consider it \"Kenough.\"',\n",
              " 'source_documents': [Document(page_content=': 37\\nReview_Date: 23 July 2023\\nAuthor: eoinageary\\nRating: 8\\nReview_Title: I am Kenough\\nReview: So I went into the movie with little to no expectations and I was pleasantly impressed with the movie overall.\\nReview_Url: /review/rw9199947/?ref_=tt_urv', metadata={'source': '/review/rw9199947/?ref_=tt_urv', 'row': 37}),\n",
              "  Document(page_content=': 20\\nReview_Date: 20 July 2023\\nAuthor: Genti25\\nRating: 8\\nReview_Title: You are Kenough\\nReview: This movie is so much fun. It starts off really strong although the story does move away from \"Barbieland\" sooner than I would have liked. Nonetheless, it regains its footing with the final act in particular and I could not stop laughing at Ryan Gosling\\'s portrayal of Ken. That song will forever be stuck in my head.\\nReview_Url: /review/rw9199947/?ref_=tt_urv', metadata={'source': '/review/rw9199947/?ref_=tt_urv', 'row': 20}),\n",
              "  Document(page_content=': 84\\nReview_Date: 23 July 2023\\nAuthor: anniebleasdale-97708\\nRating: 9\\nReview_Title: Wildly misunderstood by the poor reviewers.\\nReview: Unfortunately, most reviews that I\\'ve read here that score this film poorly explain so clearly that the reviewer did not understand the message of the film. It is not anti-men, it does not portray men as \"stupid\". Take a moment to think about how women have been portrayed in movies over the last century - oh yes, just as Ken is here! The movie exaggerates this, yes. That is the point. To clearly (and humourously) highlight the inequalities when the roles are reversed. Stop being offended by something that isn\\'t offensive and take a bit of time to actually think about the film that you have watched.\\nReview_Url: /review/rw9199947/?ref_=tt_urv', metadata={'source': '/review/rw9199947/?ref_=tt_urv', 'row': 84}),\n",
              "  Document(page_content=\": 61\\nReview_Date: 23 July 2023\\nAuthor: agjbull\\nRating: 6\\nReview_Title: Just a little empty\\nReview: I really wanted to enjoy this and I know that I am not the target audience but there were massive plot holes and no real flow. The film was very disjointed. Ryan Gosling as good as he is seemed to old to play Ken and Will Ferrell ruined every scene he was in. I just didn't get it, it seemed hollow artificial and hackneyed. A waste of some great talent. It was predictable without being reassuring and trying so hard to be woke in the most superficial way in that but trying to tick so many boxes it actually ticked none. Margo Robbie looks beautiful throughout, the costumes and the sets were amazing but the story was way too weak and didn't make much sense at all.\\nReview_Url: /review/rw9199947/?ref_=tt_urv\", metadata={'source': '/review/rw9199947/?ref_=tt_urv', 'row': 61})]}"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And with that, we have our Barbie Review RAQA Application built!"
      ],
      "metadata": {
        "id": "QQVCkoy3H5Rw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusion\n",
        "\n",
        "Now that we have our application ready, let's deploy it to a Hugging Face space with their Docker spaces.\n",
        "\n",
        "You can find the next part [here](https://ai-maker-space-barbie-raqa-application-chainlit-demo.hf.space/readme)!\n",
        "\n",
        "You've built, now it's time to ship! "
      ],
      "metadata": {
        "id": "KqIHum95dtns"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IASA1yaad6ml"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}