{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questioning Barbie and Oppenheimer Through the Use of Agents\n",
    "\n",
    "In the following notebook we will build an application that queries both the Barbie and Oppenheimer movies Wikipedia pages, as well as their reviews. \n",
    "\n",
    "The main focus of this notebook is to showcase a brief introduction to Agents.\n",
    "\n",
    "## Build 🏗️\n",
    "\n",
    "There are 3 main tasks in this notebook:\n",
    "\n",
    "1. Contruct a Barbie retriever\n",
    "2. Construct an Oppenheimer retriever\n",
    "3. Combine the two and allow users to query both resources from a single input through the use of Agents\n",
    "\n",
    "## Ship 🚢\n",
    "\n",
    "Based on Tuesday's session - construct a Chainlit (or Gradio) application that allows users to interface with the application.\n",
    "\n",
    "## Share 🚀\n",
    "\n",
    "Make a social media post about your final application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies\n",
    "\n",
    "As always, let's start with some dependencies!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U langchain openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "openai_api_key = getpass.getpass(\"Enter your OpenAI API Key: \")\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM \n",
    "\n",
    "We will be leveraging OpenAI's `gpt-3.5-turbo` throughout the notebook, and we can keep it consistent throughout!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"\", temperature = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection and Transformation\n",
    "\n",
    "We'll be leveraging the `WikipediaLoader` tool to collect information from Wikipedia. \n",
    "\n",
    "Be sure to set the `doc_content_chars_max` parameter so that you capture the *entire* Wikipedia article content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WikipediaLoader, CSVLoader\n",
    "\n",
    "barbie_wikipedia_docs = WikipediaLoader(\n",
    "    query=\"Barbie (film)\", \n",
    "    load_max_docs= # YOUR CODE HERE, \n",
    "    doc_content_chars_max=### YOUR CODE HERE\n",
    "    ).load()\n",
    "\n",
    "barbie_csv_docs = CSVLoader(\n",
    "    file_path=### YOUR CODE HERE, \n",
    "    source_column=### YOUR CODE HERE\n",
    "    ).load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we'll be using same format source documentation separated by topic, we can save ourselves some extra effort and set up our splitters once. \n",
    "\n",
    "We're going to leverage the `RecursiveCharacterTextSplitter` again, this time paying close attention to the format our Wikipedia articles and reviews are in so we can be sure to chunk them appropritately. \n",
    "\n",
    "> HINT: You can pass a list of separators when you intialize your `RecursiveTextSplitter`! They are acted on in order of element 0 -> element len(list).\n",
    "\n",
    "RELEVANT DOCS:\n",
    "- [`RecursiveCharacterTextSplitter`](https://api.python.langchain.com/en/latest/text_splitter/langchain.text_splitter.RecursiveCharacterTextSplitter.html#langchain.text_splitter.RecursiveCharacterTextSplitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "wikipedia_text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = ### YOUR CODE HERE,\n",
    "    chunk_overlap = ### YOUR CODE HERE,\n",
    "    length_function = ### YOUR CODE HERE,\n",
    "    is_separator_regex= False,\n",
    "    separators = ### YOUR CODE HERE # keep headings, then paragraphs, then sentences\n",
    ")\n",
    "\n",
    "csv_text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = ### YOUR CODE HERE,\n",
    "    chunk_overlap = ### YOUR CODE HERE,\n",
    "    length_function = ### YOUR CODE HERE,\n",
    "    is_separator_regex= False,\n",
    "    separators = ### YOUR CODE HERE # keep paragraphs, then sentences\n",
    ")\n",
    "\n",
    "chunked_barbie_wikipedia_docs = ### YOUR CODE HERE\n",
    "chunked_barbie_csv_docs = ### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieval and Embedding Strategy\n",
    "\n",
    "We've already discussed the useful application of `CacheBackedEmbeddings`, so let's do it again!\n",
    "\n",
    "RELEVANT DOCS:\n",
    "- [`CacheBackedEmbeddings`](https://api.python.langchain.com/en/latest/embeddings/langchain.embeddings.cache.CacheBackedEmbeddings.html#langchain-embeddings-cache-cachebackedembeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U rank_bm25 tiktoken faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain.storage import LocalFileStore\n",
    "\n",
    "# set up cached embeddings store\n",
    "store = ### YOUR CODE HERE\n",
    "\n",
    "core_embeddings_model = ### YOUR CODE HERE\n",
    "\n",
    "embedder = ### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll implement a `FAISS` vectorstore, and create a retriever from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barbie_csv_faiss_retriever = ### YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of excellent options to retrieve documents - we'll be looking at an additional example today, which is called the `EnsembleRetriever`.\n",
    "\n",
    "The method this is using is outlined in [this paper](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf).\n",
    "\n",
    "The brief explanation is:\n",
    "\n",
    "1. We collect results from two different retrieval methods over the same corpus\n",
    "2. We apply a reranking algorithm to rerank our source documents to be the *most relevant* without losing specific or potentially low-ranked information rich documents\n",
    "3. We feed the top-k results into the LLM with our query as context.\n",
    "\n",
    "> HINT: Your weight list should be of type `List[float]` and the `sum(List[float])` should be `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up BM25 retriever\n",
    "barbie_wikipedia_bm25_retriever = BM25Retriever.from_documents(\n",
    "    ### YOUR CODE HERE\n",
    ")\n",
    "barbie_wikipedia_bm25_retriever.k = 1\n",
    "\n",
    "# set up FAISS vector store\n",
    "barbie_wikipedia_faiss_store = FAISS.from_documents(\n",
    "    ### YOUR CODE HERE,\n",
    "    ### YOUR CODE HERE\n",
    ")\n",
    "barbie_wikipedia_faiss_retriever = barbie_wikipedia_faiss_store.as_retriever(search_kwargs={\"k\": 1})\n",
    "\n",
    "# set up ensemble retriever\n",
    "barbie_ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=### YOUR CODE HERE,\n",
    "    weights= ### YOUR CODE HERE # should sum to 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieval Agent\n",
    "\n",
    "We can create a simple conversational retrieval Agent by using the built-ins provided by LangChain!\n",
    "\n",
    "> HINT: Be sure to provide good natural language descriptions of what the tool should be used for to get the best results.\n",
    "\n",
    "RELEVANT DOCS:\n",
    "- [`create_retriever_tool`](https://api.python.langchain.com/en/latest/agents/langchain.agents.agent_toolkits.conversational_retrieval.tool.create_retriever_tool.html#langchain.agents.agent_toolkits.conversational_retrieval.tool.create_retriever_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import create_retriever_tool\n",
    "\n",
    "barbie_wikipedia_retrieval_tool = create_retriever_tool(\n",
    "    ### YOUR CODE HERE \n",
    "    ### YOUR CODE HERE\n",
    "    ### YOUR CODE HERE\n",
    ")\n",
    "\n",
    "barbie_csv_retrieval_tool = create_retriever_tool(\n",
    "    ### YOUR CODE HERE\n",
    "    ### YOUR CODE HERE\n",
    "    ### YOUR CODE HERE\n",
    ")\n",
    "\n",
    "barbie_retriever_tools = ### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've created our tools, we can combined them into an agent!\n",
    "\n",
    "RELEVANT DOCS:\n",
    "- [`create_conversational_retrieval_agent`](https://api.python.langchain.com/en/latest/agents/langchain.agents.agent_toolkits.conversational_retrieval.openai_functions.create_conversational_retrieval_agent.html#langchain.agents.agent_toolkits.conversational_retrieval.openai_functions.create_conversational_retrieval_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import create_conversational_retrieval_agent\n",
    "\n",
    "barbie_retriever_agent_executor = # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barbie_retriever_agent_executor({\"input\" : \"Did people like Barbie, or did they find it too Philosphical? If they did, can you tell me why the movie is so Philosophical?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barbie_retriever_agent_executor({\"input\" : \"What is a very quick summary of the plot of the Barbie movie?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oppenheimer Retrieval System\n",
    "\n",
    "We're going to repourpose some of what we created previously, but this time we'll explore a different multi-source retrieval system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oppenheimer_wikipedia_docs = ### YOUR CODE HERE\n",
    "\n",
    "oppenheimer_csv_docs = ### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_opp_wikipedia_docs = ### YOUR CODE HERE\n",
    "chunked_opp_csv_docs = ### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opp_csv_faiss_retriever = ### YOUR CODE HERE\n",
    "\n",
    "# set up BM25 retriever\n",
    "opp_wikipedia_bm25_retriever = ### YOUR CODE HERE\n",
    "opp_wikipedia_bm25_retriever.k = 1\n",
    "\n",
    "# set up FAISS vector store\n",
    "opp_wikipedia_faiss_store = ### YOUR CODE HERE\n",
    "opp_wikipedia_faiss_retriever = opp_wikipedia_faiss_store.as_retriever(search_kwargs={\"k\": 1})\n",
    "\n",
    "# set up ensemble retriever\n",
    "opp_ensemble_retriever = ### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-source chain\n",
    "\n",
    "We're going to allow the LLM to decide which information is most -> least valuable.\n",
    "\n",
    "The way we'll do this is with LangChain's rather powerful \"Expression Language\"!\n",
    "\n",
    "> HINT: You can leverage [this](https://python.langchain.com/docs/use_cases/question_answering/how_to/multiple_retrieval) resource if you get stuck - but experiment with different prompts/formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "system_message = \"\"\"Use the information from the below two sources to answer any questions.\n",
    "\n",
    "Source 1: public user reviews about the Oppenheimer movie\n",
    "<source1>\n",
    "{source1}\n",
    "</source1>\n",
    "\n",
    "Source 2: the wikipedia page for the Oppenheimer movie including the plot summary, cast, and production information\n",
    "<source2>\n",
    "{source2}\n",
    "</source2>\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", system_message), (\"human\", \"{question}\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oppenheimer_multisource_chain = {\n",
    "    \"source1\": (lambda x: x[\"question\"]) | opp_ensemble_retriever,\n",
    "    \"source2\": (lambda x: x[\"question\"]) | opp_csv_faiss_retriever,\n",
    "    \"question\": lambda x: x[\"question\"],\n",
    "} | prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oppenheimer_multisource_chain.invoke({\"question\" : \"What did people think of the Oppenheimer movie?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Creation\n",
    "\n",
    "Now we can finally start building our Agent!\n",
    "\n",
    "The first thing we'll need to do is provide our Agent a Toolbelt. (list of tools). Much like Batman, our LLM-powered Agent can use these tools as it sees fit. \n",
    "\n",
    "While the examples we're constructing in this notebook are straightforward for brevity and simplicities sake - there is no limit to what you can build with Agents, as we'll see as we progress through the program.\n",
    "\n",
    "So, let's begin by setting up our Tools!\n",
    "\n",
    "You'll notice that we have to set up a function to allow our `OppenheimerInfo` tool to interface with the Agent - this is due to it have a specific required input. Creating custom tools is a pattern that you'll want to grow acustomed to as you use LangChain more and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "\n",
    "def query_oppenheimer(input):\n",
    "    return oppenheimer_multisource_chain.invoke({\"question\" : input})\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = ### YOUR CODE HERE,\n",
    "        func=### YOUR CODE HERE,\n",
    "        description=### YOUR CODE HERE\n",
    "    ),\n",
    "    Tool(\n",
    "        name = ### YOUR CODE HERE,\n",
    "        func= ### YOUR CODE HERE,\n",
    "        description= ### YOUR CODE HERE\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've set up our Agents toolbelt, let's set up the LLM that will be powering it!\n",
    "\n",
    "I would suggest playing around with these prompts - and experiments to find what works best for you.\n",
    "\n",
    "RELEVANT DOCS:\n",
    "- [`ZeroShotAgent`](https://api.python.langchain.com/en/latest/agents/langchain.agents.mrkl.base.ZeroShotAgent.html#langchain-agents-mrkl-base-zeroshotagent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import ZeroShotAgent, AgentExecutor\n",
    "\n",
    "prefix = \"\"\"Have a conversation with a human, answering the following questions as best you can. You have access to the following tools:\"\"\"\n",
    "suffix = \"\"\"Begin!\"\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "prompt = ZeroShotAgent.create_prompt(\n",
    "    ### YOUR CODE HERE\n",
    "    ### YOUR CODE HERE\n",
    "    ### YOUR CODE HERE\n",
    "    ### YOUR CODE HERE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMChain\n",
    "\n",
    "llm_chain = ### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All that's left to do now is create our `ZeroShotAgent` and our `AgentExecutor`, which are the \"reasoner\" and \"actor\" halfs of the `ReAct` method of Agent implementation.\n",
    "\n",
    "Read all about the `ReAct` framework [here](https://react-lm.github.io/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barbenheimer_agent = ZeroShotAgent(\n",
    "    llm_chain=### YOUR AGENTS, \n",
    "    tools=### YOUR AGENTS, \n",
    "    verbose=### YOUR AGENTS)\n",
    "\n",
    "barbenheimer_agent_chain = AgentExecutor.from_agent_and_tools(\n",
    "    agent=### YOUR AGENTS, \n",
    "    tools=### YOUR AGENTS, \n",
    "    verbose=### YOUR AGENTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "All that is left to do now, is feed inputs to your Agent and watch it work!\n",
    "\n",
    "Remember to use the `{\"input\" : \"YOUR QUERY HERE\"}` format when prompting the Agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barbenheimer_agent_chain.invoke({\"input\" : \"What did people like about the Barbie movie?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barbenheimer_agent_chain.run({\"input\" : \"What did people like about the Oppenheimer movie?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barbenheimer_agent_chain.run({\"input\" : \"Did the movies Barbie and Oppenheimer share similar themes or ideas?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "It's time to build a Chainlit (or Gradio) application and host it on Hugging Face Spaces! :ship:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "barbenheimer-week-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
